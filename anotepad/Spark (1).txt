spark-shell --master yarn \
--conf spark.ui.port=12654

sc

sqlContext

spark-shell = scala + spark dependencies +implicit variables sc and sqlContext


sc is a webservice that runs on port 12654

localhost:8088/proxy/application_1521283016021_0001

spark-shell --help
hadoop fs -ls /user/cloudera/retail_db
hadoop fs -du -s -h /user/cloudera/retail_db

spark-shell --master yarn \
--conf spark.ui.port=12654 \
--num-executors 1 \
--executor-memory 512M


to check default configuration
cd /etc/spark/conf

vi spark-defaults.conf

vi spark-env.sh
//stop existing context

sc.stop

//Initlaize programatically

import org.apache.spark.{SparkConf, SparkContext}
val conf = new SparkConf().setAppName("Daily Revenue").setMaster("yarn-client")
val sc= new SparkContext(conf)

sc.getConf.getAll
sc.getConf.getAll.foreach(println)

val l= (1 to 1000).toList

scala> val productsRaw = scala.io.Source.fromFile("/home/cloudera/data-master/retail_db/products/part-00000").getLines
productsRaw: Iterator[String] = non-empty ite


//Creating RDD- Validating files from file system
hadoop fs -ls retail_db/orders

hadoop fs -tail retail_db/orders/part-00000


//Create RDD using spark-shell



val orders = sc.textFile("retail_db/orders")
scala> orders.first
res3: String = 1,2013-07-25 00:00:00.0,11599,CLOSED



scala> orders.take(10)
res4: Array[String] = Array(1,2013-07-25 00:00:00.0,11599,CLOSED, 2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT, 3,2013-07-25 00:00:00.0,12111,COMPLETE, 4,2013-07-25 00:00:00.0,8827,CLOSED, 5,2013-07-25 00:00:00.0,11318,COMPLETE, 6,2013-07-25 00:00:00.0,7130,COMPLETE, 7,2013-07-25 00:00:00.0,4530,COMPLETE, 8,2013-07-25 00:00:00.0,2911,PROCESSING, 9,2013-07-25 00:00:00.0,5657,PENDING_PAYMENT, 10,2013-07-25 00:00:00.0,5648,PENDING_PAYMENT)


ls -ltr /home/cloudera/data-master/retail_db/products

scala> val productsRDD = sc.parallelize(productsRaw)
productsRDD: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[2] at parallelize at <console>:29

scala> productsRDD.take(10)

scala> val l_rdd = sc.parallelize(l)
l_rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[3] at parallelize at <console>:29




val l1 = (1 to 10000).toList

//to debug in spark
scala> orders.toDebugString
res6: String = 
(1) retail_db/orders MapPartitionsRDD[1] at textFile at <console>:27 []
 |  retail_db/orders HadoopRDD[0] at textFile at <console>:27 []


scala> orders.takeSample(true, 100)
scala> orders.first
scala> orders.take(10)

scala> orders.takeSample(true, 100).foreach(println)

scala> orders.collect


sc cant read different fileformats hence use sqlContext : sqlContext.load
scala> sqlContext.read.


ls -ltr /home/cloudera/data-master/retail_db_json
scala> val ordersDF = sqlContext.read.json("retail_db_json/orders")
ordersDF: org.apache.spark.sql.DataFrame = [order_customer_id: bigint, order_date: string, order_id: bigint, order_status: string]


scala> ordersDF.show

scala> ordersDF.printSchema
root
 |-- order_customer_id: long (nullable = true)
 |-- order_date: string (nullable = true)
 |-- order_id: long (nullable = true)
 |-- order_status: string (nullable = true)

scala> ordersDF.select("order_id","order_date")
ordersDF.select("order_id","order_date").show

scala> sqlContext.load("retail_db_json/orders", "json")

val str = orders.first
str.split(",")

scala> a(0)
res2: String = 1

scala> a
res4: Array[String] = Array(1, 2013-07-25 00:00:00.0, 11599, CLOSED)

scala> val orderId=a(0)
orderId: String = 1

scala> val orderId=a(0).toInt
orderId: Int = 1

scala> a(1).contains("2017")
res5: Boolean = false

scala> a(1).contains("2013")
res6: Boolean = true
scala> val orderDate =a(1)
orderDate: String = 2013-07-25 00:00:00.0

scala> orderDate.substring(0,10)
res8: String = 2013-07-25

scala> orderDate.substring(5,7)
res9: String = 07

scala> orderDate.substring(11)
res10: String = 00:00:00.0

Replace - with /
scala> orderDate.replace('-','/')
res11: String = 2013/07/25 00:00:00.0

scala> orderDate.replace("07","July")
res12: String = 2013-July-25 00:00:00.0

scala> orderDate.indexOf("2")
res13: Int = 0

scala> orderDate.indexOf("2",2)
res14: Int = 8

scala> orderDate.length
res15: Int = 21

