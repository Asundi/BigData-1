cd flume_demo
ls -ltr

cp -rf wslogstohdfs wslogstokafka

[cloudera@quickstart flume_demo]$ cd wslogstokafka/
[cloudera@quickstart wslogstokafka]$ ls -ltr
total 4
-rw-rw-r-- 1 cloudera cloudera 541 Apr  8 23:41 example.conf

# wskafka.conf: A single-node Flume configuration
# to read data from webserver logs and publish
# to kafka topic

# Name the components on this agent
wk.sources = ws
wk.sinks = kafka
wk.channels = mem

# Describe/configure the source
wk.sources.ws.type = exec
wk.sources.ws.command = tail -F /opt/gen_logs/logs/access.log


//wskafka.conf file

# Describe the sink
wk.sinks.kafka.type = org.apache.flume.sink.kafka.KafkaSink
wk.sinks.kafka.brokerList = nn01.itversity.com:6667,nn02.itversity.com:6667,rm01.itversity.com:6667
wk.sinks.kafka.topic = fkdemodg

# Use a channel wkich buffers events in memory
wk.channels.mem.type = memory
wk.channels.mem.capacity = 1000
wk.channels.mem.transactionCapacity = 100

# Bind the source and sink to the channel
wk.sources.ws.channels = mem
wk.sinks.kafka.channel = mem

//////////////////////////////////////////////////////

flume-ng version
Flume 1.6.0-cdh5.12.0


flume-ng agent --name wk --conf-file  /home/cloudera/flume_demo/wslogstokafka/wskafka.conf

kafka-console-consumer.sh \
  --zookeeper quickstart.cloudera:2181 /kafka\
  --topic fkdemodg \
  --from-beginning

spark-submit \
--class KafkaStreamingDepartMentCount \
--master yarn \
--conf spark.ui.port=12689 \
--jars "/opt/cloudera/parcels/CDH-5.12.0-1.cdh5.12.0.p0.29/jars/spark-streaming-kafka_2.10-1.6.0-cdh5.12.0.jar, /opt/cloudera/parcels/CDH-5.12.0-1.cdh5.12.0.p0.29/jars/kafka_2.10-0.9.0-kafka-2.0.2.jar" ,/opt/cloudera/parcels/CDH-5.12.0-1.cdh5.12.0.p0.29/jars/metrics-core-2.2.0.jar \
retail_2.10-1.0.jar yarn-client

kafka_2.10-0.9.0-kafka-2.0.2.ja path correction